{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34185298",
   "metadata": {},
   "source": [
    "# Genre Classification\n",
    "\n",
    "In this notebook, you'll create a machine learning model to classify the music genre of songs. You will customize the dataset you use and the features your model will train on, and you will decide how to build and train your model in a way to maximize efficiency and accuracy.\n",
    "\n",
    "To begin, run the cell below. As always, this first cell loads the function and data necessary to run our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pointed-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import genres as ds\n",
    "\n",
    "artists, tracks, trim_tracks = ds.load_metadata('data/fma_tracks.csv') # Path to fma metadata\n",
    "full_features = ds.load_features('data/fma_features.csv', trim_tracks) # Path to fma features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e9b276",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "\n",
    "First, let's decide what data we want to use to train our model. We're going to be training our model to classify eight different genres: electronic, experimental, folk, hip-hop, instrumental, international, pop, and rock. How large should our dataset be? How many songs for each genre should we have in our dataset?\n",
    "\n",
    "Run the cell below. Next, use the sliders that appear to select how many songs you want per genre in your dataset (you can also click on the number to type instead). You can select anywhere from 0 to approximately 1000 songs for a given genre. Once you're satisfied with your selection, click the \"Build dataset\" button to finalize your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "completed-marina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5e560a969140e08b4bf4a6ff619a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='electronic', max=999), IntSlider(value=0, description='e…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = ds.display_dataset(trim_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb4c0f0",
   "metadata": {},
   "source": [
    "## 2. Features\n",
    "\n",
    "There are a number of different features we can extract from audio data. We might describe these features as being \"low-level,\" meaning that they describe attributes that are much more related to the basic structure of sound waves, as opposed to high-level features that are closer related to our perception of sounds, like mood and genre. Often times, we can use these low-level features to describe (or predict, in our case) high-level features.\n",
    "\n",
    "Now that you've finalized your dataset, you must decide which features to extract from the data so that your model can train on them. you can select up to 7 distinct features to extract from your dataset. Don't worry too much about understanding what they mean - since low-level features are so far away from the high-level features our brains are built to perceive, they might sound complicated or unintuitive. All you really need to know is that these are different ways of describing audio information in a way computers are able to easily understand. Don't be afraid to experiment and try different combinations of features at random.\n",
    "\n",
    "Here are some very brief descriptions of each of the features we'll be collecting:\n",
    "- **Chroma**: Measures how much each of the 12 pitch classes (A, Bb, B, C, etc.) are present in the audio signal.\n",
    "- **Root-mean square energy**: Kind of like the \"average\" energy, or loudness, of the audio signal.\n",
    "- **Spectral centroid**: Indicates which frequency in the audio signal has the most energy, kind of like the \"center of gravity\" of the signal.\n",
    "- **Spectral bandwith**: Describes how other frequencies are related to the spectral centroid, making it useful for describing the timbre, or sound quality, of an audio signal.\n",
    "- **Spectral rolloff**: A way of measuring the shape of an audio signal.\n",
    "- **Zero-crossing rate**: Useful for distinguishing pitched signals from percussive, or unpitched, signals.\n",
    "- **Mel-frequency cepstral coefficients**: Analyze the frequency content of an audio signal using methods similar to how our brains perceive frequency and pitch.\n",
    "\n",
    "Run the cell below. For each feature you want to extract from your data, click the corresponding checkbox. Once you're satisfied with your selection, click the \"Extract features\" button to extract your features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "paperback-awareness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3f9e6d2ce94d609fd5756e366b5350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=False, description='chroma'), Checkbox(value=False, description='rmse'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = ds.display_features(trim_tracks, data.result, full_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1d626b",
   "metadata": {},
   "source": [
    "## 3. Building the Model\n",
    "\n",
    "Now that you have features from your dataset to train on, you can start preparing your model. Before building and training it, some decisions need to be made first.\n",
    "\n",
    "First, let's split the dataset up into subsets for training, validating, and testing the model. The training data is exactly what it sounds like - it's the data that the model uses to learn how features differ across different music genres. The validation data is used to test the model's accuracy at identifying genres at checkpoints throughout the training process. Finally, the test set is used to guage the accuracy of the model once it has completed the training process.\n",
    "\n",
    "Run the cell below. Then, using the sliders that appear, select what percentages of the dataset to use for the training, validation, and test sets. **Make sure the values for each slider add up to 100.** Having a validation set is optional, but having training and test sets are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "597c1cbb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7951b5a2f4d645909f39ba05749cf94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='Training', step=10), IntSlider(value=10, description='V…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training, validation, test = ds.select_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edba212f",
   "metadata": {},
   "source": [
    "Next, let's make some final decisions about your model. One parameter we can adjust is the number of layers built in to your model. The neurons of a neural network model are grouped into layers. More layers means more neurons, though an increased layer count also comes at the cost of more computational resources and more time to train.\n",
    "\n",
    "We can also adjust the amount of time our model spends training. The training process is broken up into different segments, which are called epochs. Training a model for more epochs gives it more time to learn the data and make connections, though training for too many epochs can often lead to diminishing returns. \n",
    "\n",
    "Run the cell below. Then, using the sliders that appear, select the amount of layers and epochs you want for your model. You can select anywhere between 2 and 8 layers, as well as between 1 and 500 epochs. **Having a lot of both layers and epochs is computationally expensive, so be mindful of how you balance the two.** The maximum value you can select for each slider will get smaller as the other slider increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "respective-harris",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c86ba7149d40b0a39bae5b2a357914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=4, description='Layers', max=8, min=2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57070e4c4afd4d61a7cba0ac095e7c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=100, description='Epochs', max=500, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers, epochs = ds.select_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4c0909",
   "metadata": {},
   "source": [
    "Now the time has finally come to train your model! Once you've finished setting all your desired parameters, run the cell below. It'll process the options you've submitted, then it will build and train your model using the training and validation sets you made. The model will print out a progress bar and stats for each epoch it completes until it runs through all of them. Depending on the parameters you've chosen, it may take a few minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f14585a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 3, ..., 2, 3, 6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "remarkable-malpractice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "51/51 [==============================] - 8s 7ms/step - loss: 1.8991 - accuracy: 0.2628 - val_loss: 1.6265 - val_accuracy: 0.3986\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 1.6226 - accuracy: 0.4161 - val_loss: 1.5505 - val_accuracy: 0.4375\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 1.5160 - accuracy: 0.4618 - val_loss: 1.5210 - val_accuracy: 0.4514\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 1.4653 - accuracy: 0.4706 - val_loss: 1.5000 - val_accuracy: 0.4528\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 1.4415 - accuracy: 0.4860 - val_loss: 1.4740 - val_accuracy: 0.4667\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 1.3740 - accuracy: 0.5168 - val_loss: 1.4820 - val_accuracy: 0.4708\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 1.3760 - accuracy: 0.5123 - val_loss: 1.4805 - val_accuracy: 0.4778\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 1.3270 - accuracy: 0.5344 - val_loss: 1.4737 - val_accuracy: 0.4819\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 1.2776 - accuracy: 0.5589 - val_loss: 1.5005 - val_accuracy: 0.4875\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 1.2759 - accuracy: 0.5461 - val_loss: 1.4778 - val_accuracy: 0.4875\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 1.2190 - accuracy: 0.5745 - val_loss: 1.5167 - val_accuracy: 0.4875\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 1.1844 - accuracy: 0.5915 - val_loss: 1.5179 - val_accuracy: 0.4806\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 1.1383 - accuracy: 0.5964 - val_loss: 1.5433 - val_accuracy: 0.4764\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 1.1277 - accuracy: 0.6143 - val_loss: 1.5204 - val_accuracy: 0.4958\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 1.0852 - accuracy: 0.6256 - val_loss: 1.5686 - val_accuracy: 0.4639\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 1.0836 - accuracy: 0.6178 - val_loss: 1.5253 - val_accuracy: 0.5014\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 1.0191 - accuracy: 0.6400 - val_loss: 1.5949 - val_accuracy: 0.4667\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 1.0120 - accuracy: 0.6443 - val_loss: 1.6068 - val_accuracy: 0.4736\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.9783 - accuracy: 0.6631 - val_loss: 1.5929 - val_accuracy: 0.4833\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.9509 - accuracy: 0.6829 - val_loss: 1.6439 - val_accuracy: 0.4792\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.9230 - accuracy: 0.6923 - val_loss: 1.6751 - val_accuracy: 0.4708\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.8832 - accuracy: 0.7053 - val_loss: 1.6732 - val_accuracy: 0.4819\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.8434 - accuracy: 0.7137 - val_loss: 1.7479 - val_accuracy: 0.4806\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.8306 - accuracy: 0.7149 - val_loss: 1.7363 - val_accuracy: 0.4778\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.8017 - accuracy: 0.7308 - val_loss: 1.7364 - val_accuracy: 0.4681\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.7675 - accuracy: 0.7447 - val_loss: 1.7834 - val_accuracy: 0.4611\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.7374 - accuracy: 0.7525 - val_loss: 1.8427 - val_accuracy: 0.4472\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.7524 - accuracy: 0.7458 - val_loss: 1.8260 - val_accuracy: 0.4653\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - 0s 2ms/step - loss: 0.7137 - accuracy: 0.7548 - val_loss: 1.9072 - val_accuracy: 0.4694\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6616 - accuracy: 0.7754 - val_loss: 1.9148 - val_accuracy: 0.4556\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6684 - accuracy: 0.7801 - val_loss: 1.9225 - val_accuracy: 0.4611\n",
      "Epoch 32/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6142 - accuracy: 0.8010 - val_loss: 2.0006 - val_accuracy: 0.4500\n",
      "Epoch 33/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.6284 - accuracy: 0.7873 - val_loss: 1.9969 - val_accuracy: 0.4611\n",
      "Epoch 34/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.5696 - accuracy: 0.8141 - val_loss: 2.0115 - val_accuracy: 0.4458\n",
      "Epoch 35/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.8129 - val_loss: 2.1105 - val_accuracy: 0.4347\n",
      "Epoch 36/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.5392 - accuracy: 0.8246 - val_loss: 2.1158 - val_accuracy: 0.4625\n",
      "Epoch 37/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.5498 - accuracy: 0.8165 - val_loss: 2.1249 - val_accuracy: 0.4458\n",
      "Epoch 38/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.8441 - val_loss: 2.1635 - val_accuracy: 0.4458\n",
      "Epoch 39/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.8431 - val_loss: 2.1614 - val_accuracy: 0.4514\n",
      "Epoch 40/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.8623 - val_loss: 2.3466 - val_accuracy: 0.4361\n",
      "Epoch 41/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.8526 - val_loss: 2.2545 - val_accuracy: 0.4542\n",
      "Epoch 42/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.4266 - accuracy: 0.8700 - val_loss: 2.3932 - val_accuracy: 0.4375\n",
      "Epoch 43/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.3949 - accuracy: 0.8863 - val_loss: 2.4206 - val_accuracy: 0.4278\n",
      "Epoch 44/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.3995 - accuracy: 0.8781 - val_loss: 2.4217 - val_accuracy: 0.4458\n",
      "Epoch 45/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.3553 - accuracy: 0.8966 - val_loss: 2.4760 - val_accuracy: 0.4500\n",
      "Epoch 46/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.3481 - accuracy: 0.8991 - val_loss: 2.5519 - val_accuracy: 0.4181\n",
      "Epoch 47/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.3200 - accuracy: 0.9062 - val_loss: 2.5932 - val_accuracy: 0.4347\n",
      "Epoch 48/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.3059 - accuracy: 0.9145 - val_loss: 2.6230 - val_accuracy: 0.4375\n",
      "Epoch 49/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.2943 - accuracy: 0.9195 - val_loss: 2.6484 - val_accuracy: 0.4319\n",
      "Epoch 50/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.2773 - accuracy: 0.9283 - val_loss: 2.6952 - val_accuracy: 0.4361\n",
      "Epoch 51/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.2657 - accuracy: 0.9323 - val_loss: 2.8031 - val_accuracy: 0.4278\n",
      "Epoch 52/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.9380 - val_loss: 2.7913 - val_accuracy: 0.4194\n",
      "Epoch 53/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.2332 - accuracy: 0.9443 - val_loss: 2.8596 - val_accuracy: 0.4347\n",
      "Epoch 54/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.9440 - val_loss: 2.9151 - val_accuracy: 0.4306\n",
      "Epoch 55/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.2029 - accuracy: 0.9561 - val_loss: 2.9264 - val_accuracy: 0.4139\n",
      "Epoch 56/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1972 - accuracy: 0.9557 - val_loss: 3.0152 - val_accuracy: 0.4236\n",
      "Epoch 57/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1949 - accuracy: 0.9573 - val_loss: 3.0791 - val_accuracy: 0.4347\n",
      "Epoch 58/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1983 - accuracy: 0.9490 - val_loss: 3.1605 - val_accuracy: 0.4264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.9531 - val_loss: 3.1777 - val_accuracy: 0.4472\n",
      "Epoch 60/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1689 - accuracy: 0.9601 - val_loss: 3.2001 - val_accuracy: 0.4250\n",
      "Epoch 61/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1614 - accuracy: 0.9663 - val_loss: 3.2637 - val_accuracy: 0.4236\n",
      "Epoch 62/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1353 - accuracy: 0.9759 - val_loss: 3.2889 - val_accuracy: 0.4292\n",
      "Epoch 63/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1403 - accuracy: 0.9691 - val_loss: 3.3865 - val_accuracy: 0.4236\n",
      "Epoch 64/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1319 - accuracy: 0.9727 - val_loss: 3.3727 - val_accuracy: 0.4333\n",
      "Epoch 65/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1150 - accuracy: 0.9809 - val_loss: 3.5232 - val_accuracy: 0.4167\n",
      "Epoch 66/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1184 - accuracy: 0.9790 - val_loss: 3.4937 - val_accuracy: 0.4444\n",
      "Epoch 67/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.9813 - val_loss: 3.5603 - val_accuracy: 0.4375\n",
      "Epoch 68/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0983 - accuracy: 0.9855 - val_loss: 3.6249 - val_accuracy: 0.4444\n",
      "Epoch 69/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9795 - val_loss: 3.6662 - val_accuracy: 0.4222\n",
      "Epoch 70/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0857 - accuracy: 0.9900 - val_loss: 3.7606 - val_accuracy: 0.4222\n",
      "Epoch 71/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0808 - accuracy: 0.9884 - val_loss: 3.7879 - val_accuracy: 0.4167\n",
      "Epoch 72/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0734 - accuracy: 0.9910 - val_loss: 3.8474 - val_accuracy: 0.4250\n",
      "Epoch 73/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0657 - accuracy: 0.9947 - val_loss: 3.8952 - val_accuracy: 0.4208\n",
      "Epoch 74/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0604 - accuracy: 0.9938 - val_loss: 3.9249 - val_accuracy: 0.4167\n",
      "Epoch 75/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0778 - accuracy: 0.9876 - val_loss: 4.0241 - val_accuracy: 0.4181\n",
      "Epoch 76/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 0.9821 - val_loss: 4.0297 - val_accuracy: 0.4403\n",
      "Epoch 77/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1015 - accuracy: 0.9776 - val_loss: 4.1019 - val_accuracy: 0.4194\n",
      "Epoch 78/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 0.9602 - val_loss: 4.0604 - val_accuracy: 0.4347\n",
      "Epoch 79/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1222 - accuracy: 0.9673 - val_loss: 4.1214 - val_accuracy: 0.4306\n",
      "Epoch 80/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.1018 - accuracy: 0.9748 - val_loss: 4.2910 - val_accuracy: 0.4278\n",
      "Epoch 81/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0888 - accuracy: 0.9795 - val_loss: 4.3164 - val_accuracy: 0.4181\n",
      "Epoch 82/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0834 - accuracy: 0.9821 - val_loss: 4.3555 - val_accuracy: 0.4139\n",
      "Epoch 83/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9935 - val_loss: 4.3717 - val_accuracy: 0.4167\n",
      "Epoch 84/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0396 - accuracy: 0.9975 - val_loss: 4.3373 - val_accuracy: 0.4292\n",
      "Epoch 85/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 0.9995 - val_loss: 4.3836 - val_accuracy: 0.4306\n",
      "Epoch 86/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 4.4283 - val_accuracy: 0.4222\n",
      "Epoch 87/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 0.9999 - val_loss: 4.4554 - val_accuracy: 0.4292\n",
      "Epoch 88/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 4.4884 - val_accuracy: 0.4319\n",
      "Epoch 89/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 4.5519 - val_accuracy: 0.4264\n",
      "Epoch 90/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 4.5512 - val_accuracy: 0.4264\n",
      "Epoch 91/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0169 - accuracy: 0.9999 - val_loss: 4.6263 - val_accuracy: 0.4306\n",
      "Epoch 92/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 4.6508 - val_accuracy: 0.4292\n",
      "Epoch 93/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0190 - accuracy: 0.9997 - val_loss: 4.6788 - val_accuracy: 0.4333\n",
      "Epoch 94/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0169 - accuracy: 0.9998 - val_loss: 4.7112 - val_accuracy: 0.4236\n",
      "Epoch 95/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 0.9998 - val_loss: 4.7689 - val_accuracy: 0.4306\n",
      "Epoch 96/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 0.9999 - val_loss: 4.7977 - val_accuracy: 0.4181\n",
      "Epoch 97/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0140 - accuracy: 0.9998 - val_loss: 4.8238 - val_accuracy: 0.4361\n",
      "Epoch 98/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0137 - accuracy: 0.9998 - val_loss: 4.8797 - val_accuracy: 0.4236\n",
      "Epoch 99/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0184 - accuracy: 0.9987 - val_loss: 5.1543 - val_accuracy: 0.4236\n",
      "Epoch 100/100\n",
      "51/51 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9700 - val_loss: 5.1574 - val_accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "ds.param_check(training.value, validation.value, test.value)\n",
    "train_data, test_data = ds.preprocessing(features.result, test.value)\n",
    "model = ds.build_model(train_data, layers.value)\n",
    "ds.train_model(model, train_data, epochs.value, validation.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76e1132",
   "metadata": {},
   "source": [
    "## 4. Testing the Model\n",
    "\n",
    "Once your model has finished training, you can test it by running the cell below. The model will use the test dataset as a way of checking its accuracy. Once it's done testing, it'll print out the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.test_model(model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f9551d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
