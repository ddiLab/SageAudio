{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14286cf",
   "metadata": {},
   "source": [
    "# Event-Detecting Audio Recorder using Waggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f9a20e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using backwards compatible implementation of time_ns\n"
     ]
    }
   ],
   "source": [
    "from waggle.data.audio import Microphone\n",
    "from waggle.data.audio import AudioFolder\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import soundfile\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80ed8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record_events() # # # # # # #\n",
    "#\n",
    "# sr: sample rate\n",
    "# threshold: energy cutoff point\n",
    "# record_len: amount of frames to record\n",
    "# frame_len: length of a frame in seconds\n",
    "# buffer_len: length of buffer in frames\n",
    "# path: path to write wav files to\n",
    "# verbose: level of output to write\n",
    "#\n",
    "# # # # # # # # # # # # # # # #\n",
    "def record_events(sr, threshold, frame_len, buffer_len, record_len, path, verbose):\n",
    "    # establish variables\n",
    "    job_list = deque()\n",
    "    job_flags = deque()\n",
    "    buffer = []\n",
    "    record_elapse = 0\n",
    "    save_count = 0\n",
    "    early_event = -1\n",
    "    late_event = -1\n",
    "    wave_len = (buffer_len * 2) + 1 # length in frames of full recording\n",
    "    event_frames = [] # list of frames that were determined to be events\n",
    "    \n",
    "    # initialize microphone\n",
    "    microphone = Microphone()\n",
    "    \n",
    "    # clear directory\n",
    "    delete_events(path)\n",
    "    \n",
    "    # Begin record loop\n",
    "    print_info(1, verbose, \"* Beginning recording cycle...\")\n",
    "    while record_elapse < record_len:\n",
    "    \n",
    "        # Record frame and append to end of buffer\n",
    "        frame = microphone.record(frame_len)\n",
    "        buffer.append(frame)\n",
    "        print_info(2, verbose, f\"\\n** Frame {record_elapse + 1}\")\n",
    "        \n",
    "        # if there are jobs, handle them\n",
    "        if len(job_list):\n",
    "            for cnt, flag in enumerate(job_flags):\n",
    "                job_flags[cnt] = flag - 1\n",
    "            \n",
    "            # Save and delete completed jobs\n",
    "            if job_flags[0] == 0:\n",
    "                wave = np.append(frames_to_wave(job_list[0]), frames_to_wave(buffer[-(buffer_len):]))\n",
    "                soundfile.write(path + f\"{datetime.now()}.wav\", wave, sr)\n",
    "                print_info(3, verbose, f\"*** Saved event {save_count} (length: {len(job_list[0])} frames) on frame {record_elapse}, jobs remaining: {len(job_list)}\")\n",
    "                save_count += 1\n",
    "                job_list.popleft()\n",
    "                job_flags.popleft()\n",
    "                \n",
    "        # Check if frame passes threshold\n",
    "        if np.max(frame.data) > threshold:\n",
    "            # mark frame as an event\n",
    "            event_frames.append(record_elapse)\n",
    "            \n",
    "            # if we haven't filled the buffer yet, note when the early event was detected\n",
    "            if record_elapse < buffer_len and early_event == -1:\n",
    "                early_event = record_elapse\n",
    "                job_list.append(buffer[:])\n",
    "                job_flags.append(buffer_len)\n",
    "                print_info(2, verbose, f\"** Event detected on frame {record_elapse} (early)\")\n",
    "            # if we've reached the final buffer, note when the late event was detected\n",
    "            elif record_elapse >= record_len - buffer_len and late_event == -1:\n",
    "                late_event = record_len - record_elapse\n",
    "                print_info(2, verbose, f\"** Event detected on frame {record_elapse} (late)\")\n",
    "            # if event isn't early or late, then add as a job\n",
    "            else:\n",
    "                job_list.append(buffer[-(buffer_len):])\n",
    "                job_flags.append(buffer_len)\n",
    "                print_info(2, verbose, f\"** Event detected on frame {record_elapse}\")\n",
    "            \n",
    "        # increment loop counter\n",
    "        record_elapse += 1\n",
    "        \n",
    "    # If there is a late event, save it\n",
    "    if late_event != -1:\n",
    "        wave = frames_to_wave(buffer[-(2*buffer_len):])\n",
    "        soundfile.write(path + f\"{datetime.now()}.wav\", wave, sr)\n",
    "        print_info(3, verbose, f\"*** Saved event {save_count} on frame {record_elapse}, jobs remaining: {len(job_list)}\")\n",
    "        save_count += 1\n",
    "    \n",
    "    # when finished, print statistics\n",
    "    print_info(1, verbose, f\"\\n* Done recording. Events saved: {save_count}\")\n",
    "    \n",
    "    # run analysis\n",
    "    full_wave = frames_to_wave(buffer)\n",
    "    time = np.arange(0, len(full_wave) / sr, 1/sr)\n",
    "    frame_in_samples = sr * frame_len\n",
    "    \n",
    "    # full buffer analysis\n",
    "    plt.figure(figsize=(17, 5))\n",
    "    plt.axes(ybound=(-1, 1))\n",
    "    plt.title(f\"Full Recording\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.plot(time, full_wave)\n",
    "    plt.axhline(0, color='k')\n",
    "    plt.axhline(threshold, color='r')\n",
    "    plt.grid(axis='x', markevery=buffer_len)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # event analysis\n",
    "    dataset = AudioFolder(path)\n",
    "        \n",
    "    for cnt, sample in enumerate(dataset):\n",
    "        time = np.arange(0, len(sample.data) / sample.samplerate, 1/sample.samplerate)\n",
    "    \n",
    "        plt.figure(cnt, figsize=(17, 5))\n",
    "        plt.axes(ybound=(-1, 1))\n",
    "        plt.title(f\"Event {cnt + 1}\")\n",
    "        plt.xlabel(\"Time [s]\")\n",
    "        plt.plot(time, sample.data) # plot full event\n",
    "        plt.axhline(0, color='k')\n",
    "        plt.axhline(threshold, color='r') # plot threshold line\n",
    "        plt.grid(axis='x', markevery=buffer_len)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "649a6bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_to_wave(buffer):\n",
    "    wave = np.array([])\n",
    "    for i in buffer:\n",
    "        wave = np.append(wave, i.data)\n",
    "        \n",
    "    return wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b9ffbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(mode, verbose, message):\n",
    "    if mode <= int(verbose):\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44a7c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_events(path):\n",
    "    for x in os.listdir(path):\n",
    "        if x[-4:] == \".wav\":\n",
    "            os.unlink(f\"{path}/{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b47fde3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b280b927ca03493ea53865421a851441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedIntText(value=48000, description='Sample rate', max=100000, step=100), FloatSlideâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact_ui = widgets.interact_manual(record_events,\n",
    "            sr = widgets.BoundedIntText(value=48000, min=0, max=100000, step=100, description='Sample rate', indent=10),\n",
    "            threshold = widgets.FloatSlider(value=0.2, min=0, max=1.0, step=0.01, description='Threshold',\n",
    "                        continuous_update=False, readout_format='.2f'),\n",
    "            frame_len = widgets.BoundedIntText(value=5, min=1, max=7200, step=1, description='Frame length'),\n",
    "            buffer_len = widgets.BoundedIntText(value=1, min=0, max=100, step=1, description='Buffer size'),\n",
    "            record_len = widgets.BoundedIntText(value=5, min=0, step=1, description='Record size'),\n",
    "            path = widgets.Text(value='audio_files/', description='Folder path:'),\n",
    "            verbose = widgets.Dropdown(options=['0', '1', '2', '3'], value='1', description='Verbosity:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ff20a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
