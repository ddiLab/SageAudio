{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34185298",
   "metadata": {},
   "source": [
    "# Genre Classification\n",
    "\n",
    "In this notebook, you'll create a machine learning model to classify the music genre of songs. You will customize the dataset you use and the features your model will train on, and you will decide how to build and train your model in a way to maximize efficiency and accuracy.\n",
    "\n",
    "To begin, run the cell below. As always, this first cell loads the function and data necessary to run our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-foundation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "import genres_full as gs\n",
    "\n",
    "artists, tracks, data = gs.load_metadata('/data/Genres_Full/tracks.csv') # Path to fma metadata\n",
    "features = gs.load_features('/data/Genres_Full/fma_small.csv', data) # Path to fma features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48854b33",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "\n",
    "Before we can build and train a model, we need to prepare the data it's going to be using.\n",
    "\n",
    "First, let's split the dataset up into subsets for training, validating, and testing the model. The training data is exactly what it sounds like - it's the data that the model uses to learn how features differ across different music genres. The validation data is used to test the model's accuracy at identifying genres at checkpoints throughout the training process. Finally, the test set is used to guage the accuracy of the model once it has completed the training process.\n",
    "\n",
    "Run the cell below. Then, using the sliders that appear, select how many songs from the dataset to use for the training, validation, and test sets. **The dataset contains 7997 songs in total, so your subsets will (at most) total 7997 songs together.** You are not required to use all 7997 songs, but you can't go over. Each subset must have at least 1 song in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41880b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation, test = gs.select_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a3d077",
   "metadata": {},
   "source": [
    "Now let's decide what we want our training subset to look like. We're going to be training our model to classify eight different genres: electronic, experimental, folk, hip-hop, instrumental, international, pop, and rock. How many songs for each genre should we have in our training set?\n",
    "\n",
    "Run the cell below. Next, use the sliders that appear to select how many songs you want per genre in your training set (you can also click on the number to type instead). Each genre has approximately 1000 songs in it, though keep in mind that some of these songs will be reserved for your validation and test sets. **Keep an eye on the total amount of songs in your training set - don't go over the limit you set for your training set previously.** A warning message will pop up to let you know if you need to dial back your selections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89958866",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = gs.select_dataset(training.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3265847",
   "metadata": {},
   "source": [
    "## 2. Features\n",
    "\n",
    "There are a number of different features we can extract from audio data. We might describe these features as being \"low-level,\" meaning that they describe attributes that are much more related to the basic structure of sound waves, as opposed to high-level features that are closer related to our perception of sounds, like mood and genre. Often times, we can use these low-level features to describe (or predict, in our case) high-level features.\n",
    "\n",
    "Now that you've finalized your dataset, you must decide which features to extract from the data so that your model can train on them. you can select up to 7 distinct features to extract from your dataset. Don't worry too much about understanding what they mean - since low-level features are so far away from the high-level features our brains are built to perceive, they might sound complicated or unintuitive. All you really need to know is that these are different ways of describing audio information in a way computers are able to easily understand. Don't be afraid to experiment and try different combinations of features at random.\n",
    "\n",
    "Here are some very brief descriptions of each of the features we'll be collecting:\n",
    "- **Chroma**: Measures how much each of the 12 pitch classes (A, Bb, B, C, etc.) are present in the audio signal.\n",
    "- **Root-mean square energy**: Kind of like the \"average\" energy, or loudness, of the audio signal.\n",
    "- **Spectral centroid**: Indicates which frequency in the audio signal has the most energy, kind of like the \"center of gravity\" of the signal.\n",
    "- **Spectral bandwith**: Describes how other frequencies are related to the spectral centroid, making it useful for describing the timbre, or sound quality, of an audio signal.\n",
    "- **Spectral rolloff**: A way of measuring the shape of an audio signal.\n",
    "- **Zero-crossing rate**: Useful for distinguishing pitched signals from percussive, or unpitched, signals.\n",
    "- **Mel-frequency cepstral coefficients**: Analyze the frequency content of an audio signal using methods similar to how our brains perceive frequency and pitch.\n",
    "\n",
    "Run the cell below. For each feature you want to extract from your data, click the corresponding checkbox. Once you're satisfied with your selection, click the \"Extract features\" button to extract your features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200cbf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = gs.select_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d4022b",
   "metadata": {},
   "source": [
    "## 3. Building the Model\n",
    "Next, let's make some final decisions about your model. One parameter we can adjust is the number of layers built in to your model. The neurons of a neural network model are grouped into layers. More layers means more neurons, though an increased layer count also comes at the cost of more computational resources and more time to train.\n",
    "\n",
    "We can also adjust the amount of time our model spends training. The training process is broken up into different segments, which are called epochs. Training a model for more epochs gives it more time to learn the data and make connections, though training for too many epochs can often lead to diminishing returns. \n",
    "\n",
    "Run the cell below. Then, using the sliders that appear, select the amount of layers and epochs you want for your model. You can select anywhere between 2 and 8 layers, as well as between 1 and 500 epochs. **Having a lot of both layers and epochs is computationally expensive, so be mindful of how you balance the two.** The maximum value you can select for each slider will get smaller as the other slider increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204a7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers, epochs = gs.select_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf6d072",
   "metadata": {},
   "source": [
    "## 4. Training the Model\n",
    "Now the time has finally come to train your model! Once you've finished setting all your desired parameters, run the cell below. It'll process the options you've submitted, then it will build and train your model using the training and validation sets you made. The model will print out a progress bar and stats for each epoch it completes until it runs through all of them. Depending on the parameters you've chosen, it may take a few minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47169d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data, encoder = gs.preprocessing(full_features, tracks, genres, features, \n",
    "                                                            training, validation, test)\n",
    "model = gs.build_model(train_data, layers.value)\n",
    "gs.train_model(model, train_data, val_data, epochs.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f9aaf4",
   "metadata": {},
   "source": [
    "## 5. Testing the Model\n",
    "\n",
    "Once your model has finished training, you can test it by running the cell below. The model will use the test dataset as a way of checking its accuracy. Once it's done testing, it'll print out the model's accuracy as well as 10 of the predictions it made on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e8dffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.test_model(model, test_data, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3cf4af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
