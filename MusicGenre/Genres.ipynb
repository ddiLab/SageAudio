{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf717e77",
   "metadata": {},
   "source": [
    "# Genre Classification\n",
    "This notebook builds a model using data from the FMA dataset to classify the genre of user-submitted audio.\n",
    "\n",
    "Outline:\n",
    "1. Build model\n",
    "2. Get test audio\n",
    "3. Classify test audio\n",
    "\n",
    "Sources:\n",
    "- [FMA: A Dataset For Music Analysis](https://github.com/mdeff/fma) by MichaÃ«l Defferrard, et. al. Provides the dataset used in this notebook.\n",
    "- [Audio Data Analysis Using Deep Learning with Python](https://www.kdnuggets.com/2020/02/audio-data-analysis-deep-learning-python-part-1.html), by Nagesh Singh Chauhan, writing for KDnuggets. This notebook is written using the same basic concepts and implementation presented in this article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa252a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b1f63b",
   "metadata": {},
   "source": [
    "## 1. Build model\n",
    "Here, we use the small subset of the FMA dataset to build our model. `fma_small` contains 8000 30s long tracks, representing a total of eight genres:\n",
    "1. Electronic\n",
    "2. Experimental\n",
    "3. Folk\n",
    "4. Hip-Hop\n",
    "5. Instrumental\n",
    "6. International\n",
    "7. Pop\n",
    "8. Rock\n",
    "\n",
    "Each of these genres are evenly represented among the dataset, i.e. 1000 tracks per genre.\n",
    "\n",
    "Before we can build our model, we first need to load and prepare the data. Rather than use the raw audio data to build our model, we use extracted features from the audio to represent it. Reference `Features.ipynb` for more information on which features we are using and how we extracted them. Here, we will load `fma_small.csv`, a file containing the features of the `fma_small` dataset produced by `Features.ipynb`.\n",
    "\n",
    "Once we have our data prepared, we build and fit an artifical neural network (ANN) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8f2e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENRE_LIST = 'electronic experimental folk hip-hop instrumental international pop rock'.split()\n",
    "GENRE_CNT = 8\n",
    "FEATURES = 'fma_small.csv'\n",
    "\n",
    "# Load features and trim filename column\n",
    "data = pd.read_csv(FEATURES)\n",
    "data = data.drop(['filename'],axis=1)\n",
    "\n",
    "# Encoding the labels\n",
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(genre_list)\n",
    "\n",
    "# Scaling the feature columns\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
    "\n",
    "# Dividing data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0838b58a",
   "metadata": {},
   "source": [
    "Now that we have our data set up, we can build and fit our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9722801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(GENRE_CNT, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "classifier = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba030b51",
   "metadata": {},
   "source": [
    "## 2. Get test audio\n",
    "Now that we've built our model, we can get our test audio sorted out. To upload audio you want to classify with this model, navigate to the `./test_audio` directory and place audio files in their corresponding genre folder. The cell below will establish the directories as necessary if they have not already been made. Once you've finished placing your audio files in their respective folders, run the next cell to extract all of their features into `test_features.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca5ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish upload directories\n",
    "try:\n",
    "    os.mkdir('./test_audio')\n",
    "    print('Directory ./test_audio created.')\n",
    "except:\n",
    "    print('./test_audio already exists.')\n",
    "finally:\n",
    "    for g in GENRE_LIST:\n",
    "        try:\n",
    "            os.mkdir(f'./test_audio/{g}')\n",
    "            print(f'Directory ./test_audio/{g} created.')\n",
    "        except:\n",
    "            print(f'./test_audio/{g} already exists.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab4be3c",
   "metadata": {},
   "source": [
    "Now we can extract features from our test audio. For more information on how we do so, take a look at `Features.ipynb`, where we use the same method to extract features for our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bf2d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create header for test_features.csv\n",
    "header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "for i in range(1, 21):\n",
    "    header += f' mfcc{i}'\n",
    "header += ' label'\n",
    "header = header.split()\n",
    "\n",
    "# Write header to file\n",
    "file = open('test_features.csv', 'w', newline='')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    \n",
    "# Feature extraction\n",
    "for g in GENRE_LIST:\n",
    "    for filename in os.listdir(f'./test_audio/{g}'):\n",
    "        # Load audio and extract features\n",
    "        songname = f'./test_audio/{g}/{filename}'\n",
    "        y, sr = librosa.load(songname, mono=True, duration=30)\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        \n",
    "        # Write feature labels\n",
    "        to_append = f'{filename.replace(\" \", \"_\")} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    \n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "    \n",
    "        # Write genre labels\n",
    "        label = g.capitalize()\n",
    "        if label == 'Hip-hop':\n",
    "            label = 'Hip-Hop'\n",
    "        to_append += f' {label}'\n",
    "        \n",
    "        # Write to file\n",
    "        file = open('test_features.csv', 'a', newline='')\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cc1bb7",
   "metadata": {},
   "source": [
    "Now that we've extracted the features from our test audio, let's format the data so our model can understand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3539aadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and trim data\n",
    "data = pd.read_csv('test_features.csv')\n",
    "filenames = data['filename']\n",
    "data = data.drop(['filename'],axis=1)\n",
    "\n",
    "# Encoding the Labels\n",
    "genre_list = data.iloc[:, -1]\n",
    "y_test = encoder.transform(genre_list)\n",
    "\n",
    "#Scaling the Feature columns\n",
    "scaler = StandardScaler()\n",
    "X_test = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaba193",
   "metadata": {},
   "source": [
    "## 3. Classify test audio\n",
    "Now that we've done everything we need to get the model and our test data set up, let's have the model try and classify the genre of our test audio.\n",
    "\n",
    "The sample output might look something like this:\n",
    "\n",
    "```\n",
    "Results:  \n",
    "50/50 - 0s - loss: 7.6068 - accuracy: 0.4281\n",
    "\n",
    "Predictions:  \n",
    "filename.wav: Rock (87.15%) - SUCCESS\n",
    "filename.mp3: Electronic (75.44%) - FAILURE\n",
    "etc.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ef6aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run predictions\n",
    "print('Results:')\n",
    "test_scores = model.evaluate(X_test, y_test, verbose=2)\n",
    "predictions = model.predict(X_test[:])\n",
    "\n",
    "# Save predictions\n",
    "results = []\n",
    "nums = []\n",
    "for i in predictions:\n",
    "    highest = 0\n",
    "    cnt = 0\n",
    "    for j in i:\n",
    "        if j > i[highest]:\n",
    "            highest = cnt\n",
    "        cnt += 1\n",
    "    results.append(highest)\n",
    "    nums.append(i[highest])\n",
    "\n",
    "# Mark successes and failures\n",
    "success = []\n",
    "cnt = 0\n",
    "for i in results:\n",
    "    if i == y_test[cnt]:\n",
    "        success.append(\"SUCCESS\")\n",
    "    else:\n",
    "        success.append(\"FAILURE\")\n",
    "    cnt += 1\n",
    "\n",
    "# Print individual results\n",
    "results = encoder.inverse_transform(results)\n",
    "print('\\nPredictions:')\n",
    "cnt = 0\n",
    "for i in filenames:\n",
    "    print('{}: {} ({:.2%}) - {}'.format(filenames[cnt], results[cnt], nums[cnt], success[cnt]))\n",
    "    cnt += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
