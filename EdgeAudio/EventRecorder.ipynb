{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14286cf",
   "metadata": {},
   "source": [
    "# Event-Detecting Audio Recorder\n",
    "\n",
    "This notebook leverages the PyWaggle library and prior work from SageEdu to record and visualize audio detected automatically over a recording period. Only sounds that pass a loudness threshold are saved to file. After the notebook is finished recording, it plots waveform visualiziations of the saved sounds and of the full recording period. \n",
    "\n",
    "To use this notebook, run all of the cells. The final cell produces a user interface for configuring and starting the recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9a20e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from waggle.data.audio import Microphone\n",
    "from waggle.data.audio import AudioFolder\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import soundfile\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edd0de5",
   "metadata": {},
   "source": [
    "### Primary record function\n",
    "\n",
    "The recording process occurs in chunks called frames, which are defined by the user as being *f* seconds long. The notebook records one frame at a time, testing each new frame against the energy threshold to determine whether or not it contains an event. When an event is found, that frame is set aside until enough frames have been recorded to fill a buffer window around the frame. The event frame is then saved as a .wav file with *b* frames of buffer on either side of it. Note that, due to this buffer system, during the first and last *b* frames of the recording process, no events will be detected or saved.\n",
    "\n",
    "After recording *n* frames, the notebook draws visualizations of both the full *n(f)*-second recording and each individually saved event. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ede328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record_events() # # # # # # #\n",
    "#\n",
    "# sr: sample rate in hz\n",
    "# threshold: energy cutoff point\n",
    "# frame_len: length of a frame in seconds\n",
    "# buffer_len: length of buffer in frames\n",
    "# record_len: amount of frames to record\n",
    "# path: path to write wav files to\n",
    "# verbose: level of output to write\n",
    "#\n",
    "# # # # # # # # # # # # # # # #\n",
    "def record_events(sr, threshold, frame_len, buffer_len, record_len, path, verbose):\n",
    "    ### Pre-loop initialization\n",
    "    # establish variables\n",
    "    job_list = deque()\n",
    "    buffer = []\n",
    "    record_elapse = 0\n",
    "    save_count = 0\n",
    "    wave_len = (buffer_len * 2) + 1 # length in frames of full recording\n",
    "    event_frames = [] # list of frames that were determined to be events\n",
    "    wave_frames = 1 + (2 * buffer_len) # length of an event in frames\n",
    "    wave_seconds = wave_frames * frame_len # length of an event in seconds\n",
    "    \n",
    "    # initialize microphone\n",
    "    microphone = Microphone()\n",
    "    \n",
    "    # clear directory\n",
    "    delete_events(path)\n",
    "    \n",
    "    ### Recording Loop\n",
    "    print_info(1, verbose, \"* Beginning recording cycle...\")\n",
    "    while record_elapse < record_len:\n",
    "    \n",
    "        # record frame and append to end of buffer\n",
    "        frame = microphone.record(frame_len)\n",
    "        buffer.append(frame)\n",
    "        print_info(2, verbose, f\"\\n** Frame {record_elapse + 1}\")\n",
    "        \n",
    "        # if there are jobs, handle them\n",
    "        if len(job_list):\n",
    "            for cnt, job in enumerate(job_list):\n",
    "                job_list[cnt] = np.append(job, [record_elapse])\n",
    "            \n",
    "            # save and delete completed jobs\n",
    "            if len(job_list[0]) == (wave_frames):\n",
    "                wave = indeces_to_wave(buffer, job_list[0][0], job_list[0][-1])\n",
    "                soundfile.write(path + f\"{save_count}.wav\", wave, sr)\n",
    "                print_info(3, verbose, f\"*** Saved event {save_count}\")\n",
    "                save_count += 1\n",
    "                job_list.popleft()\n",
    "                \n",
    "        # check if frame passes threshold\n",
    "        if np.max(frame.data) > threshold:\n",
    "            # if event isn't early or late, then add as a job\n",
    "            if record_elapse > buffer_len and record_elapse < (record_len - buffer_len):\n",
    "                job_list.append(np.arange(record_elapse-buffer_len-1, record_elapse))\n",
    "                event_frames.append(record_elapse-buffer_len-1)\n",
    "                print_info(2, verbose, f\"** Event detected on frame {record_elapse}\")\n",
    "            \n",
    "        # increment loop counter\n",
    "        record_elapse += 1\n",
    "    \n",
    "    ### Post-loop prints\n",
    "    print_info(1, verbose, f\"\\n* Done recording. Events saved: {save_count}\")\n",
    "    print_info(1, verbose, f\"Files saved to {path}:\")\n",
    "    print_events(path)\n",
    "    \n",
    "    ### Analysis\n",
    "    # initializing stuff\n",
    "    full_wave = frames_to_wave(buffer)\n",
    "    time = np.arange(0, len(full_wave) / sr, 1/sr)\n",
    "    frame_in_samples = sr * frame_len\n",
    "    xticks = np.arange(0, frame_len*record_len, frame_len)\n",
    "    \n",
    "    # full buffer analysis\n",
    "    plt.figure(figsize=(17, 5))\n",
    "    plt.axes(xlim=(0, frame_len*record_len), xticks=(xticks), ylim=(-1, 1))\n",
    "    plt.title(f\"Full Recording\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.plot(time, full_wave)\n",
    "    plt.axhline(0, color='k')\n",
    "    plt.axhline(threshold, color='r')\n",
    "    plt.grid(axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # event analysis\n",
    "    dataset = AudioFolder(path)\n",
    "        \n",
    "    for cnt, sample in enumerate(dataset):\n",
    "        time = np.arange(0, len(sample.data) / sample.samplerate, 1/sample.samplerate)\n",
    "        time += (event_frames[cnt]*frame_len)\n",
    "    \n",
    "        plt.figure(cnt, figsize=(17, 5))\n",
    "        plt.axes(xticks=(xticks), ylim=(-1, 1))\n",
    "        plt.title(f\"Event {cnt}\")\n",
    "        plt.xlabel(\"Time [s]\")\n",
    "        plt.plot(time, sample.data) # plot event\n",
    "        plt.axhline(0, color='k')\n",
    "        plt.axhline(threshold, color='r') # plot threshold line\n",
    "        plt.grid(axis='x')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0337fe02",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "Various subroutines to assist in processing and writing audio files, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649a6bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a list of frames, return a single concatenated np array of the wave.\n",
    "# buffer - a list of np array waves\n",
    "def frames_to_wave(buffer):\n",
    "    wave = np.array([])\n",
    "    for i in buffer:\n",
    "        wave = np.append(wave, i.data)\n",
    "        \n",
    "    return wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2f89de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given start and stop indeces, call frames_to_wave on a subset of a given list of frames.\n",
    "# buffer - a list of np array waves\n",
    "# start - start index\n",
    "# stop - stop index\n",
    "def indeces_to_wave(buffer, start, stop):\n",
    "    return frames_to_wave(buffer[start:stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ffbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a given message if the mode is less than or equal to the verbosity.\n",
    "# mode - the verbosity level of the given message\n",
    "# verbose - the user verbosity level\n",
    "# message - the message to print\n",
    "def print_info(mode, verbose, message):\n",
    "    if mode <= int(verbose):\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a7c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all .wav files in the given directory.\n",
    "# path - the directory to search\n",
    "def delete_events(path):\n",
    "    for x in os.listdir(path):\n",
    "        if x[-4:] == \".wav\":\n",
    "            os.unlink(f\"{path}/{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82452e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the name of all the .wav files in the given directory.\n",
    "# path - the directory to search\n",
    "def print_events(path):\n",
    "    for x in os.listdir(path):\n",
    "        if x[-4:] == \".wav\":\n",
    "            print(f\"{x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df8e3f3",
   "metadata": {},
   "source": [
    "### Record and plot events\n",
    "\n",
    "Running the cell below will generate an interface you can use to adjust the recording settings. Here are what each of the controls mean:\n",
    "\n",
    "- **Sample rate** - Sets the sample rate of the recording in Hz. Default is 48000Hz.\n",
    "- **Threshold** - Sets the energy magnitude at which a sound is recognized as an event. Default is 0.20, and can be adjusted between 0.00 and 1.00.\n",
    "- **Frame length** - Defines the length of a single frame in *seconds*. Default is 5 seconds.\n",
    "- **Buffer size** - Defines the length of the buffer in *frames.* For example if the buffer is set to 1, then when a frame is found to contain an event, the exported file will include that frame as well as one frame immediately before and immediately after it. Default is 1 frame.\n",
    "- **Record size** - Defines how many *frames* should be recorded in total. Default is 5 frames.\n",
    "- **Folder path** - Determines the directory to save .wav files to. Defaults to ``audio_files/``.\n",
    "- **Verbosity** - Determines the amount of system text to output during the recording process. Verbosity 0 will generate no text output; verbosity 1 will generate start and stop messages; and verbosity 2 and 3 will generate more detailed output about how the recording process is running.\n",
    "\n",
    "Once you have adjusted the settings to your liking, click the **Run Interact** button to begin recording. Once the recording is finished, it will list the names of the audio files saved during the process, and then it will draw waveform plots of the full recording and each of the saved events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b47fde3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interact_ui = widgets.interact_manual(record_events,\n",
    "            sr = widgets.BoundedIntText(value=48000, min=0, max=100000, step=100, description='Sample rate', indent=10),\n",
    "            threshold = widgets.FloatSlider(value=0.2, min=0, max=1.0, step=0.01, description='Threshold',\n",
    "                        continuous_update=False, readout_format='.2f'),\n",
    "            frame_len = widgets.BoundedIntText(value=5, min=1, max=7200, step=1, description='Frame length'),\n",
    "            buffer_len = widgets.BoundedIntText(value=1, min=0, max=100, step=1, description='Buffer size'),\n",
    "            record_len = widgets.BoundedIntText(value=5, min=0, step=1, description='Record size'),\n",
    "            path = widgets.Text(value='audio_files/', description='Folder path:'),\n",
    "            verbose = widgets.Dropdown(options=['0', '1', '2', '3'], value='1', description='Verbosity:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cbbfa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
