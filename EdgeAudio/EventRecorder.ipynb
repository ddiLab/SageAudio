{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14286cf",
   "metadata": {},
   "source": [
    "# Event-Detecting Audio Recorder using Waggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e96023e",
   "metadata": {},
   "source": [
    "This notebook, based on previous work from the [SageEdu](https://github.com/ddiLab/SageEdu/tree/main/microphone) project, utilizes the PyWaggle library to make an audio recorder that can detect when there is sound to record.\n",
    "\n",
    "When run, the notebook records for a predetermined amount of cycles, each of which is of a predetermined length. At the end of each cycle, the notebook briefly pauses recording so that it can go back and analyze the cycle in segments (frames). For each frame, the notebooks compares the maximum energy that occurs in it to a predetermined cutoff point. If it falls below the cutoff point, then the frame is discarded. The remaining frames are recombined, creating a number of audio events which are then saved to file. This way, the notebook only saves the parts of its recordings that actually contain sound information. After completing this step, the notebook begins the next cycle and resumes recording.\n",
    "\n",
    "An analysis routine written for [SageEdu](https://github.com/ddiLab/SageEdu/blob/main/microphone/WaggleAudio.ipynb) can be run on events that have been recorded as well, printing basic information about the sound files and plotting their waveforms. Additionally, there is a routine to delete all previously recorded events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d622bf9",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72782e4",
   "metadata": {},
   "source": [
    "This sections contains our library imports and our function declarations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from waggle.data.audio import Microphone\n",
    "from waggle.data.audio import AudioFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import soundfile\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226a5d1e",
   "metadata": {},
   "source": [
    "``record_events()`` is the primary recording routine. The user passes in a number of parameters to control aspects like the amount of cycles, the length of cycles, the cutoff energy, etc. As explained above, the notebook records for a given number of cycles, ending each cycle by looping through each frame it has just recorded and deciding whether to save it or discard it based on its max energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f989fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_events(cycle, length, cutoff, sr, frame, path, overwrite):\n",
    "    if overwrite:\n",
    "        delete_events(path)\n",
    "    \n",
    "    microphone = Microphone()\n",
    "    cycle_cnt = 1\n",
    "    event_cnt_global = 0\n",
    "    while True:\n",
    "    \n",
    "        if cycle_cnt-1 == cycle:\n",
    "            break\n",
    "\n",
    "        # record sample\n",
    "        print(f\"recording cycle {cycle_cnt}...\")\n",
    "        sample = microphone.record(length)\n",
    "        event = False\n",
    "        event_cnt = 0\n",
    "        data = np.array([])\n",
    "    \n",
    "        # analyze sample by frames\n",
    "        print(f\"cycle {cycle_cnt} finished recording. analyzing for events...\")\n",
    "        for i in range(0, len(sample.data), frame): \n",
    "            # calculate max amplitude of current frame\n",
    "            current_frame = sample.data[i:i+frame]\n",
    "            max_current_frame = np.max(current_frame)\n",
    "            if event: # if we're currently in an event,\n",
    "                if max_current_frame > cutoff: # if event is still ongoing,\n",
    "                    data = np.append(data, current_frame)\n",
    "                else: # if event has ended,\n",
    "                    event = False\n",
    "                    event_cnt += 1\n",
    "                    write_path = f\"{path}/event_{cycle_cnt}_{event_cnt}.wav\"\n",
    "                    soundfile.write(str(write_path), np.append(data, current_frame), sr)\n",
    "                    data = np.array([])\n",
    "            else: # if we're not currently in an event\n",
    "                if max_current_frame > cutoff: # if event has started,\n",
    "                    event = True\n",
    "                    data = np.append(data, current_frame)\n",
    "                \n",
    "        if event: # if cycle ends in the middle of an event, save it\n",
    "            event_cnt += 1\n",
    "            write_path = f\"{path}/event_{cycle_cnt}_{event_cnt}.wav\"\n",
    "            soundfile.write(str(write_path), np.append(data, sample.data[-frame:]), sr)\n",
    "            \n",
    "        print(f\"{event_cnt} events detected in cycle {cycle_cnt}\\n\")                \n",
    "        \n",
    "        cycle_cnt += 1\n",
    "        event_cnt_global += event_cnt\n",
    "    \n",
    "    print(f\"\\n{cycle} cycles completed! {event_cnt_global} total events recorded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2526cdc2",
   "metadata": {},
   "source": [
    "``analyze_events``iterates through a directory containing audio files and prints each file's sample rate, initial and final data points, and a waveform plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfd9a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_events(path):\n",
    "    dataset = AudioFolder(\"audio_files\") # desired directory\n",
    "    x = 0\n",
    "    for sample in dataset:\n",
    "        link = str(dataset.files[x])\n",
    "        print(f'samplerate: {sample.samplerate} \\ntimestamp: {sample.timestamp} \\ndata:\\n{sample.data}\\n\\n')\n",
    "        time2 = np.arange(0, len(sample.data) / sample.samplerate, 1/sample.samplerate)\n",
    "    \n",
    "        plt.figure(x)\n",
    "        plt.title(link)\n",
    "        plt.xlabel(\"Time [s]\")\n",
    "        plt.plot(time2, sample.data)\n",
    "        plt.show()\n",
    "        x += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0815ad59",
   "metadata": {},
   "source": [
    "``delete_events`` iterates through a directory and deletes all audio files of previously recorded events it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388d8cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_events(path):\n",
    "    for x in os.listdir(path):\n",
    "        if x[:6] == \"event_\":\n",
    "            os.unlink(f\"{path}/{x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d62aab",
   "metadata": {},
   "source": [
    "## Running the Recorder\n",
    "\n",
    "With our setup complete, we can now get to recording. The cell below declares all parameters used in the three functions established above:\n",
    "\n",
    "- ``cycle`` - the amount of cycles to record for.\n",
    "- ``length`` - the length, in seconds, of a recording cycle.\n",
    "- ``cutoff`` - the energy point at which the recorder considers something to be an event. Calibrating this to the particular recording environment will take some experimentation. In my experience, 0.03 has worked as a good default. Using ``analyze_events`` can help give you an idea of what some of the recorded energies in your files look like.\n",
    "- ``sr`` - the sample rate of the recordings, defaults to 48000.\n",
    "- ``frame`` - the length of a frame in samples. To define it in seconds, multiply the amount of seconds by sr. Defaults to 1 second.\n",
    "- ``path`` - the path of the directory to save audio files to. This path is also used when running the other two functions.\n",
    "- ``overwrite`` - when set to true, the notebook will run ``delete_events`` before recording.\n",
    "\n",
    "Once you've adjusted the parameters to your liking, run the cell, then run the cells below to run the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle = 3 # amount of recording cycles\n",
    "length = 30 # length of recording cycles in seconds\n",
    "cutoff = 0.03 # cutoff point for deciding whether something is an event (default = 0.05)\n",
    "sr = 48000 # sample rate (default = 48000)\n",
    "frame = sr # frame size in samples (default = sr (48000))\n",
    "path = \"audio_files\"\n",
    "overwrite = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb537fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_events(cycle, length, cutoff, sr, frame, path, overwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b469c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_events(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec8f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_events(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
